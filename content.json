{"meta":{"title":"Blog","subtitle":"","description":"Euphonium的个人博客","author":"Euphonium","url":"http://www.euphonium.cn","root":"/"},"pages":[{"title":"Repositories","date":"2020-02-08T06:26:33.448Z","updated":"2020-02-08T06:26:33.448Z","comments":false,"path":"repository/index.html","permalink":"http://www.euphonium.cn/repository/index.html","excerpt":"","text":""},{"title":"tags","date":"2020-02-08T11:35:12.000Z","updated":"2020-02-08T11:46:52.421Z","comments":false,"path":"tags/index.html","permalink":"http://www.euphonium.cn/tags/index.html","excerpt":"","text":""},{"title":"关于我","date":"2020-02-08T11:57:55.000Z","updated":"2020-02-09T06:18:20.213Z","comments":false,"path":"about/index.html","permalink":"http://www.euphonium.cn/about/index.html","excerpt":"","text":"本人985本科工科男，目前在深圳上学。出于兴趣、记录学习过程和自我提高搭建此个人博客。目前4大爱好：日漫、足球、coding和游戏。 日漫最爱京阿尼日常系动画，山田尚子是神！现在是我的最主要的休闲方式，自从大一被舍友带入二次元后深陷其中无法自拔。 足球2010年的南非让我爱上巴西，大一关注英超爱上利物浦。终身是巴西利物浦的双料球迷。足球是人生二大信仰之一。 coding身为计算机专业学生曾经也对专业曾经迷茫过。不过最近终于找到了自己喜欢的方向，目前正在为成为出色的后端开发工程师努力学习中。偏爱Java 游戏十年Dota2玩家，虽然现在已经是云玩家，不过它也是我的青春，是我的除足球外另外一个人生信仰。除此之外偶尔玩点各类战略类游戏。P社，光荣系列，全战系列，文明之类 图片墙 各位姥爷记得打赏呀＼(￣▽￣)／"}],"posts":[{"title":"logstash学习笔记","slug":"logstash学习笔记","date":"2020-02-12T00:45:03.000Z","updated":"2020-02-12T03:06:25.358Z","comments":true,"path":"2020/02/12/logstash学习笔记/","link":"","permalink":"http://www.euphonium.cn/2020/02/12/logstash%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","excerpt":"","text":"前言这是2019年12月到2020年1月前后一个半月在一家公司实习时部门要求做的任务。原来的这个时候已经回公司接着实习了，但由于疫情学校和公司都不让实习生回去实习。这个学习笔记我在公司内部已经总结过一次了但文档不让拷贝出来，今天就重新总结一下过去两个月实习学的东西。 正文logstash简介Logstash是一个开源的服务器端数据处理管道，可以同时从多个数据源获取数据，并对其进行转换，然后将其发送到你最喜欢的“存储”。它是elastic系列下的一个产品。通常业界常说它跟Elasticsearch和Kibana共同构成ELK是当下流行的日志搜集和展示解决方案。 Logstash主要用到三个模块：input、filter、output。 Input可以从很多地方输入，比如：stdin、tcp/udp对应端口监听、数据库jdbc注入等等。在公司自测用的是从tcp端口输入。Filter是我实习期间工作的重点，主要用到以下几个插件kv, dissect, translate, date, mutate, grok这些将在后面部分涉及。其中filter可以开多个pipeline来增加处理效率。Output主要部分就是输出，主要应该输出到目标存储上，我开发自测是输出到stdout。 filter插件实习期间90%的时间都是在写这个部分内容，处理各种各样的输入然后转换成一种类似键值对的格式输出到对应存储。我的学习过程主要来自官方文档https://www.elastic.co/guide/en/logstash/current/index.html和项目的以前代码。以下学习笔记内容来自官方文档 grok主要作用是解析非结构化数据，通过正则表达式。可以说是是最万能的但效率最差，可以用别的办法处理就不要grok 12345filter &#123; grok &#123; match &#x3D;&gt; &#123; &quot;message&quot; &#x3D;&gt; &quot;%&#123;IP:client&#125; %&#123;WORD:method&#125; %&#123;URIPATHPARAM:request&#125; %&#123;NUMBER:bytes&#125; %&#123;NUMBER:duration&#125;&quot; &#125; &#125;&#125; 比如上述代码就是一个正则匹配，如果匹配成功则把message字段（这个是输入数据的默认字段）解析成client, method, request, bytes, duration。这些字段。而前面的IP,WORD则是系统内置的正则表达式，比如IP可以解析IPv4和IPv6，NUMBER解析数字。看下面例子： 155.3.244.1 GET &#x2F;index.html 15824 0.043 会被上面的filter解析成 12345client: 55.3.244.1method: GETrequest: &#x2F;index.htmlbytes: 15824duration: 0.043 当然你也可以自己写解析格式（其实7成情况都是自己写的）格式如下 1(?&lt;field_name&gt;the pattern here) 就比如说上述的%{NUMBER:duration}可以改写为 1(?&lt;duration&gt;\\d+\\.?\\d+) grok的match功能支持将信息匹配多个正则解析式。按照顺序进行匹配，如果已经匹配到了就不用匹配后面的正则解析式。不过用多个解析式匹配非常影响效率。 dissect使用分隔符将非结构化事件数据提取到字段中。其实大体作用跟grok差不多，都是用于非结构化数据。但dissect提取效率更高，grok适用的情况更多。 基本匹配形式：%{a} %{b} %{c}。其中a,b,c为字段名。通过a,b,c中间的空格进行分隔，例如见下：信息例子： 1John Smith,Big Oaks,Wood Lane,Hambledown,Canterbury,CB34RY filter部分： 1234567filter &#123; dissect &#123; mapping &#x3D;&gt; &#123; &quot;message&quot; &#x3D;&gt; &quot;%&#123;name&#125;,%&#123;addr1&#125;,%&#123;addr2&#125;,%&#123;addr3&#125;,%&#123;city&#125;,%&#123;zip&#125;&quot; &#125; &#125;&#125; 结果： 123456&quot;name&quot;: &quot;Jane Doe&quot;,&quot;addr1&quot;: &quot;4321 Fifth Avenue&quot;,&quot;addr2&quot;: &quot;&quot;,&quot;addr3&quot;: &quot;&quot;,&quot;city&quot;: &quot;New York&quot;&quot;zip&quot;: &quot;87432&quot; dissect插件常用的方法就是上面的例子。其中匹配操作还可以用的“&amp;？+/”等符号，详细见官方文档。因为实际操作中我基本没用到过就不展开了。 kv键值对匹配的常用解析插件，非常好用，效率也高。但对数据的格式要求很高。 详细使用通过下面例子描述 123456789101112filter &#123; kv &#123; field_split &#x3D;&gt; &quot;;&quot; #键值对和键值对之间的分隔符，默认为&quot; &quot; value_split &#x3D;&gt; &quot;:&quot; #键值对中间分隔符，默认为&quot;:&quot; include_keys &#x3D;&gt; [ &quot;from&quot;, &quot;to&quot; ] #只提取这些key值，其他的不提取 source &#x3D;&gt; &quot;not_the_message&quot; #执行kv操作的字段值。默认为message &#125; &#125; date目前接触的主要用处都是通过前面三种的插件提取的时间解析信息字段，然后直接进行替换到@timestamp字段。详细代码： 123456date &#123; match &#x3D;&gt; [&quot;tim&quot;, &quot;yyyy-MM-dd HH:mm:ss&quot;, &quot;UNIX&quot;] #将tim字段按照 target &#x3D;&gt; &quot;@timestamp&quot; #将tim按照覆盖到时间戳 timezone &#x3D;&gt; &quot;+08:00&quot; #中国东八区 # remove_field &#x3D;&gt; [&quot;tim&quot;] #这是删除字段公共方法，详细见后 &#125; 注意UNIX时间。这是从1970年1月1日午夜开始经过的秒数。实习的时候刚开始遇到过。 translate有点类似switch case的作用。就是将一个字段映射到另外一个字段的值。 详细见代码： 1234567891011121314151617filter &#123; translate &#123; field &#x3D;&gt; &quot;[http_status]&quot; #相当于switch中间的那个字段 destination &#x3D;&gt; &quot;[http_status_description]&quot; #目标字段 dictionary &#x3D;&gt; &#123; &quot;100&quot; &#x3D;&gt; &quot;Continue&quot; &quot;101&quot; &#x3D;&gt; &quot;Switching Protocols&quot; &quot;200&quot; &#x3D;&gt; &quot;OK&quot; &quot;500&quot; &#x3D;&gt; &quot;Server Error&quot; &#125; #从源头到目标字段的映射关系 fallback &#x3D;&gt; &quot;I&#39;m a teapot&quot; #如果源头字段的值没有出现在&quot;dictionary&quot;中则用fallback。相当于default &#125; &#125; mutate很重要的后续处理插件，主要用于将解析后的字段进行处理比如改变数据类型、重命名、分割和连接、字符串大小写处理等。基本上前面的部分解析完要写入存储中，为了完成对应字段的映射以及数据格式的转换，都要靠mutate插件。convert 转换数据类型 12345678filter &#123; mutate &#123; convert &#x3D;&gt; &#123; &quot;fieldname&quot; &#x3D;&gt; &quot;integer&quot; &quot;booleanfield&quot; &#x3D;&gt; &quot;boolean&quot; &#125; &#125; &#125; rename 字段重新命名（最常用） 123456filter &#123; mutate &#123; # Renames the &#39;HOSTORIP&#39; field to &#39;client_ip&#39; rename &#x3D;&gt; &#123; &quot;HOSTORIP&quot; &#x3D;&gt; &quot;client_ip&quot; &#125; &#125; &#125; update 直接给字段赋值 12345filter &#123; mutate &#123; update &#x3D;&gt; &#123; &quot;sample&quot; &#x3D;&gt; &quot;My new message&quot; &#125; &#125; &#125; 剩下还有很多方法，详细见官方文档 补充公共方法可以出现在上述任何一个插件中。主要用到add_field, remove_field这两个 123456filter &#123; translate &#123; add_field &#x3D;&gt; &#123; &quot;message2&quot; &#x3D;&gt; &quot;Hello world&quot; &#125; remove_field &#x3D;&gt; [&quot;time&quot;] &#125; &#125; tag_on_failure这也是一个方法。用于标记匹配失败。像grok, kv, dissect这些可能会出现匹配失败的插件才有的方法。例子见下。 123456filter &#123; grok &#123; match &#x3D;&gt; &#123; &quot;message&quot; &#x3D;&gt; &quot;%&#123;IP:client&#125; %&#123;WORD:method&#125; %&#123;URIPATHPARAM:request&#125; %&#123;NUMBER:bytes&#125; %&#123;NUMBER:duration&#125;&quot; &#125; tag_on_failure &#x3D;&gt; [&quot;parsefailure&quot;] &#125;&#125; 这个时候如果grok正则匹配失败则tags字段会多出一个”parsefailure”值。其中tags字段专门用于记录错误匹配。 注意：tag_on_failure是错误处理，不要用作程序的业务逻辑。一般都是标记这些匹配失败的例子专门记录到一个日志或文件中。不要通过tag_on_failure来写你的正常执行逻辑。 例子见下： 1234567891011filter &#123; grok &#123; match &#x3D;&gt; &#123; &quot;message&quot; &#x3D;&gt; &quot;%&#123;IP:client&#125; %&#123;WORD:method&#125; %&#123;URIPATHPARAM:request&#125; %&#123;NUMBER:bytes&#125; %&#123;NUMBER:duration&#125;&quot; &#125; tag_on_failure &#x3D;&gt; [&quot;parsefailure&quot;] &#125; if &quot;parsefailure&quot; not int [tags] &#123; mutate &#123; ...... &#125; &#125;&#125; 通过条件判断让已经出错的信息跳到最末尾执行。成功匹配的才进行后面的逻辑。 总结其实实习过程中我也能感觉到这是一个简单的业务。因为根据这个系统的架构我不用操心input和output的部分（项目以前的代码有通用的过滤器进行处理）我只用写filter的部分拓展可以处理的信息种类即可。 差不多从实习开始两周配环境和熟悉了整个从开发到本机自测到自动化测试到git提交到写文档整个流程。后面一个月基本按照组长要求的速度完成任务。我对自己的这两个月打70分吧。因为刚开始的熟悉流程花的时间有点久。希望接下来的实习生活可以吸取教训提高效率。","categories":[],"tags":[{"name":"logstash","slug":"logstash","permalink":"http://www.euphonium.cn/tags/logstash/"}]},{"title":"Linux-shell脚本学习","slug":"Linux-shell脚本学习","date":"2020-02-11T14:05:57.000Z","updated":"2020-02-11T14:08:44.982Z","comments":true,"path":"2020/02/11/Linux-shell脚本学习/","link":"","permalink":"http://www.euphonium.cn/2020/02/11/Linux-shell%E8%84%9A%E6%9C%AC%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"补充此博文转载自我的github仓库https://github.com/euphonium1998/Shell。为2020-02-01撰写。后续部分为原博文内容 Linux shell (bash shell) 学习过程本人学习Linux主要通过《鸟哥的Linux私房菜》进行学习，shell同理。两天阅读shell的四个章节，前三章通读，最后一章shell脚本细读。 然后今天晚上完成shell章节课后练习题共6道。比较简单而且网络上例子也很多，故较快完成。 运行环境本人使用虚拟机Ubuntu以及在Windows系统下用git内嵌shell进行编写调试 程序实例 user_pwd.sh 脚本功能： 输出目前用户名称以及目前的工作目录。 输入指令： sh ./user_pwd.sh birthday.sh 脚本功能： 以”yyyy-mm-dd”格式输入自己的下一个生日，输出目前日期离你过生日还差少天。 输入指令： sh ./birthday.sh [date] eg：sh ./birthday.sh 2020-04-16 sum.sh 脚本功能： 输入一个整数n，输出1加到n的和 输入指令： sh ./sum.sh [n] eg: sh ./sum.sh 10 file.sh 脚本功能： 判断当前目录是否有名称为”logical”文件。如果没有则用touch建立该文件。如果存在该文件且不为目录，则删除该文件并创建名称为”logical”的目录。如果存在该文件且为目前，则删除该目录。（正好执行三遍从创建到销毁） 输入指令： sh ./file.sh passwd.sh 脚本功能： 提取/etc/passwd的用户名并打印 输入指令： sh ./passwd.sh guess.sh 脚本功能： 系统生成0~99的随机数，而用户进行输入来猜猜数字 输入指令： sh ./guess.sh 主要遇到问题额。其实没遇到啥问题。主要就是if循环 if [ condition ]; then 必须要有空格隔开，语法还不太熟。再者就是grep、cut的用法还不太熟练 总结总的来说基本学会了shell的语法，但做到以后在公司熟练编写shell脚本还是有一定距离，因为目前linux指令还不是很熟。 shell脚本就是像python脚本一样，常常用于批处理。但因为效率问题肯定是不能写服务器后端。对于开发工程师而言是一门很好的辅助语言跟python一样。 同时发现其实最近在公司实习的时候是有接触过shell的。比如/etc/init.d/fantom restart就是通过shell实现的。所以其实很多程序在后台的重启、关闭、调试是通过shell脚本的。其实shell脚本就是一批命令的集合罢了。 接下来计划学习mysql和设计模式了。疫情导致书还没发货但没办法只能看电子书了。","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://www.euphonium.cn/tags/Linux/"},{"name":"shell","slug":"shell","permalink":"http://www.euphonium.cn/tags/shell/"}]},{"title":"Java多线程 生产者消费者模型","slug":"Java多线程-生产者消费者模型","date":"2020-02-11T14:00:39.000Z","updated":"2020-02-11T14:06:54.684Z","comments":true,"path":"2020/02/11/Java多线程-生产者消费者模型/","link":"","permalink":"http://www.euphonium.cn/2020/02/11/Java%E5%A4%9A%E7%BA%BF%E7%A8%8B-%E7%94%9F%E4%BA%A7%E8%80%85%E6%B6%88%E8%B4%B9%E8%80%85%E6%A8%A1%E5%9E%8B/","excerpt":"","text":"补充此博文转载自我的github仓库https://github.com/euphonium1998/Java-Thread。为2020-01-30撰写。后续部分为原博文内容 Java 多线程 代码问题背景 模拟病人去医生看病的过程，n个病人去看病，有m个医生。医院有k个座位，病人在座位上排队，如果座位满了则这个病人出去逛一下过一段时间再回来。 将这个问题抽象成生产者-消费者模型。医生是消费者，病人是生产者。座位是仓库。 编译器作者本机编译器：JDK13 不过应该JDK1.5之后的都可以用，看用到的核心代码的源码的部分全部都是“since 1.5” 输入参数在\\out\\production\\Thread目录下有编译好的.class文件 输入以下指令： java Main [doctorNum] [patientNum] [seatNum] 例如： java Main 2 10 3 表示有2个医生，10个病人，3个座位 用到核心技术 atomic类用作计数器 BlockingQueue用来保证仓库的存和取线程安全 ReentrantLock用来保证存储打印顺序的正确性 学习过程首先感谢廖雪峰Java教程，这个网站可以用于简单的将JavaSE过一遍，基本的功能都有介绍。但要真正做到精通还是需要阅读经典书籍。等过一阵子基本开发必备知识都学完后再读《Java核心技术》 下面部分作为学习笔记记录这次学习收获： 明白一些Java多线程的基本概念，比如线程之间的状态和转换，线程的启动方式有两种继承父类Thread或者重写Runnable，守护进程的定义，进程的优先级等等。 synchronized的同步方法，以及和它互相协作的函数wait，notify。 从JDK1.5开始引进了ReentrantLock和Condition。Condition的await、signal函数和ReentrantLock配合使用可以替代synchronized、wait，notify。ReentrantLock是个更加轻量级的锁，同时可以通过tryLock这种机制避免死锁，更加灵活。 明白理解和乐观锁和悲观锁。乐观锁是假设读取过程内容没有被改变，只在结束时进行校验，如果改变了就要上锁重新读取一遍。而悲观锁则是在读取刚开始就上锁防止别的线程不管是读还是写都禁止访问。显然乐观锁适合用于读多写少的情况，悲观锁适合用于读少写多的情况。ReentrantLock是悲观锁，StampedLock则可以实现乐观锁。同时CAS机制也可以算作一种乐观锁。 学会并使用了BlockingQueue。通过阅读它的源码发现它是用ReentrantLock和Condition实现的。Java还有实现了其他的线程安全集合，比如ConcurrentHashMap等等。 了解使用Atomic类，通过CAS的方法实现线程安全，适合用作累加器、计数器 初步了解了用Executors创建线程池的方法，在本次代码初步阶段也是使用线程池来实现医生线程。不过后面由于线程编号的问题无法实现，所以放弃使用线程池。不过在阅读网上资料过程中发现用Executors初始化线程存在很大弊端，工业上常用ThreadPoolExecutor创建线程池。 遇到问题即解决 ClassCastExcception： 这个问题主要是在初期BlockingQueue从主线程传参给医生和病人线程的时候出现问题。原来想用接口编程的，像List和ArrayList一样。但是chuangdi传递给其他类的时候报错了。所以最后就统一用ArrayBlockingQueue这个类来实现阻塞队列了。 打印顺序无序 每个线程操作阻塞队列的时候都保证了有序性。但打印信息的时候却是无序的。所以我用ReentrantLock将操作阻塞队列外面又加了一层锁。医生和病人线程同时只有一个可以操作阻塞队列（忽然发现那这样用阻塞队列的意义是什么。。用普通不就行了吗？）。同时要防止两种死锁出现：在某个医生线程获得锁后调用quue.take()引起线程挂起但没有释放外层的锁，以及某个病人获得外层锁后queue.put()引起线程挂起的死锁情况。这两种情况要先做条件判断后再执行后面语句。 主要以上两个问题（其实主要就是问题2，以及更改过程中延伸出的其他小问题） 总结算是一次最初级的Java多线程练手。主要是改写上学期的用C语言实现的操作系统实验，总的感觉和C相比，Java的很多多线程操作都封装好了，不用自己mutex，pthread_create自己实现阻塞队列之类的。但是因为封装好了所以加锁的地方就可能不是个人想要的地方，就会出现实际操作正确但打印无序的新问题。 同时这次编码还有一些东西没有用到，比如线程池的使用，ThreadLocal的使用。离熟悉Java多线程还有一段路要走。 一个晚上学习，一个晚上编码，一个下午写README.md。感觉效率还行，多线程先告一段落，接下来学习shell脚本。","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.euphonium.cn/tags/Java/"},{"name":"多线程","slug":"多线程","permalink":"http://www.euphonium.cn/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"hexo博客搭建与部署","slug":"hexo博客搭建与部署","date":"2020-02-10T12:06:59.000Z","updated":"2020-02-10T14:41:39.347Z","comments":true,"path":"2020/02/10/hexo博客搭建与部署/","link":"","permalink":"http://www.euphonium.cn/2020/02/10/hexo%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E4%B8%8E%E9%83%A8%E7%BD%B2/","excerpt":"","text":"前言其实作者本人早在2019年12月就有了建立博客的打算。但由于之前的实习以及其他优先级更高的事情导致自己建立博客这件事一直被延期。终于在春节期间找到空闲时间从2.6号开始用三个晚上时间建立博客并部署到自己的阿里云服务器上。今天2.10号抽出时间写一下建站过程。 先贴出我搭建博客主要的参考的资料，感谢以下作者的帮助。 B站Up主：CodeSheep hexo主题：cofess的pure主题。Github地址: https://github.com/cofess 其他nginx服务器和hexo博客的配置命令参考的博文百度上太多了我也忘了我看的是谁的了。 2.6日 本机部署hexo博客这个部分参考主要参考B站up主CodeSheep的搭建过程。因为我用的还是windows系统，所以不要用cmd操作，用git bash会好一些。 hexo博客的原理hexo博客是基于node.js开发的静态博客。静态博客简单说就是用html、css、js写的网页。它没有后端，无法登陆注册账号。显示单纯的网页给用户看。 用户一般基于markdown格式写博客。然后用hexo命令将其生成网页的相关静态资源，之后再发布。 hexo本机搭建步骤 下载Node.js、git npm install -g hexo-cli如果觉得速度慢可以下载用cnpm然后用中国的镜像。不过我还是用npm。 在你想要保存博客程序的目录hexo init hexo g 生成public目录。里面存着目前你写的博文网页的静态资源。 hexo s开启服务器。可以通过localhost:4000访问，主要用于调试。默认有一个hello页面。 首先我将hexo博客先部署到自己的Github Pages。注意要先创建一个github的仓库，且仓库名字一定要按照格式。比如我的github名字是name123那么仓库名字一定要为name123.github.io 改变hexo的配置文件_config.yml找到如下部分按照如下添加: 1234deploy: type: git repo: https:&#x2F;&#x2F;github.com&#x2F;name123&#x2F;name123.github.io.git &#x2F;&#x2F;就是刚刚创建的仓库地址，前面的是一个例子 branch: master 在博客目录执行npm install hexo-deployer-git --save这个东西用于部署到Github Pages 现在开始可以写博客了。按照我下面的步骤操作绝对没问题。 12345hexo new &quot;新博文的名字&quot;进入source&#x2F;_post目录可以看到刚刚创建的.md博客。打开，markdown格式写博客.....hexo clean &#x2F;&#x2F;清理public目录hexo g &#x2F;&#x2F;生产现在的网站静态资源hexo d &#x2F;&#x2F;推到刚刚的仓库 现在登录网页输入name123.github.io（就是刚刚创建的仓库名字）就可以看到刚刚部署的博客了（会有延迟） 进阶方面：如果你想要你的博客有标签、分类、关于我之类的东西。执行hexo new page tags就可以初始化标签功能。其他也如此。详细的这里就不介绍了。 总结按照上述步骤即可完成博客部署到Github上。如果不满足于此可以看接下来的部分，部署到自己的阿里云服务器上。 其实这个部分很快就可以搞定，差不多一个小时。那天的后面部分就是买阿里云的服务器，进行远程连接，更改阿里云配置等。注意买的虚拟机默认80端口是关的，需要去打开。详细操作百度，这里不介绍了。 这个博文可能会漏一些部分（毕竟是搭完后才写的），如果配置过程不成功请自行搜索问题和思考问题。 2.7日 博客部署阿里云nginx服务器nginx服务器下载和部署注意：以下操作部分均在阿里云机上进行操作 yum install -y nginx安装nginx。nginx启动服务器。这个时候访问你的服务器ip就可以看到默认页面了。非常神奇它居然是centos的欢迎页。不知道阿里云改了啥配置 vim /etc/nginx/nginx.conf进入nginx的配置文件。见下图 红框部分告诉我们可以自己写个conf配置文件放到/etc/nginx/conf.d/目录所以我创建文件touch blog.conf。然后用vim编辑文件 123456server&#123; listen 80; server_name ;&#x2F;&#x2F;这里填云机ip或者域名 root ;&#x2F;&#x2F;这里填你服务器存放hexo静态资源的绝对路径 location &#x2F; &#123; &#125; 详细关于nginx的配置文件细节自行去了解 git拉取网站静态资源这个部分相对简单。就是git clone从上一章节讲的仓库拉取资源即可。拉取到之前server配置的文件夹即可。 2.8-2.9日 选取主题，美化博客这个部分就比较简单了。因为我个人只是想用博客所以前端的一些东西了解不深，所以拉取的主题会有一些多余的功能，我做到可以完成我的审美要求即可，有些功能删掉了。 步骤基本如下： 上网找到喜欢的主题 找到那个主题的github仓库。拉取下来。 按照它的安装流程改配置文件。这里特别注意。有两个配置文件主题目录下的配置文件和博客的配置文件。都是_config.yml。主要改主题目录下的配置文件，但博客的那个配置文件也要改，首先要改默认主题，如果你想用中文显示就要改语言配置，详细如下：1language: zh-CN &#x2F;&#x2F;改为中文 1theme: pure &#x2F;&#x2F;新主题名为pure 最重要的是默认主题要改当然你的主题必须支持中文。这个看你的主题目录下的languages目录有没有对应的语言支持.yml文件 总结hexo是个很简单的博客系统，非常容易搭建没啥技术。这次博客搭建主要的目的就是给自己搭一个写东西的平台。同时也通过实践学到了一些东西比如跟服务器，跟html相关的东西。 后续几天会把前阵子的东西从github搬过来，同时写一下过去一个月实习的学习笔记。然后打算写设计模式和数据库相关的学习笔记。","categories":[],"tags":[{"name":"博客","slug":"博客","permalink":"http://www.euphonium.cn/tags/%E5%8D%9A%E5%AE%A2/"}]}]}